{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specter Embeddings\n",
    "Delvin\n",
    "\n",
    "This notebook\n",
    "1) preps SickKids IPE + Urology Datasets for embedding\n",
    "2) performs inference to embed the abstracts\n",
    "\n",
    "Output is a .jsonl file to be parsed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow instructions for setting up specter per: https://github.com/allenai/specter\n",
    "\n",
    "Then, download datasets_complete and unzip into `specter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasets_complete/*'\n",
    "out_dir = 'datasets_json'\n",
    "\n",
    "if not os.path.exists(out_dir): os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = glob('datasets_complete/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vitamin_D\n",
      "Hydronephrosis\n",
      "Scaling\n",
      "Rehab\n",
      "NCDs\n",
      "ADIPP\n",
      "Fragility_of_BBD\n",
      "WASH\n"
     ]
    }
   ],
   "source": [
    "for fn in f: \n",
    "    basen = os.path.basename(fn)\n",
    "    txt = os.path.splitext(basen)[0]\n",
    "    txt = txt.split('_')[0].replace(' ', '_')\n",
    "\n",
    "    print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_complete/Vitamin D_complete2.csv\n",
      "datasets_json/Vitamin_D.json\n",
      "datasets_complete/Hydronephrosis_FQ_complete.csv\n",
      "datasets_json/Hydronephrosis.json\n",
      "datasets_complete/Scaling_complete.csv\n",
      "datasets_json/Scaling.json\n",
      "datasets_complete/Rehab_complete.csv\n",
      "datasets_json/Rehab.json\n",
      "datasets_complete/NCDs_complete_2020_07_15.csv\n",
      "datasets_json/NCDs.json\n",
      "datasets_complete/ADIPP_complete.csv\n",
      "datasets_json/ADIPP.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dso/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_complete/Fragility of BBD_complete.csv\n",
      "datasets_json/Fragility_of_BBD.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dso/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets_complete/WASH_complete.csv\n",
      "datasets_json/WASH.json\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for fn in f:\n",
    "    # construct new filename for json and ids\n",
    "    print(fn)\n",
    "    basen = os.path.basename(fn)\n",
    "    txt = os.path.splitext(basen)[0]\n",
    "    txt = txt.split('_')[0].replace(' ', '_')\n",
    "    out_json = os.path.join(out_dir, '{}.json'.format(txt))\n",
    "    out_ids = os.path.join(out_dir, '{}.ids'.format(txt))\n",
    "    print(out_json)\n",
    "    \n",
    "    # read in each file and dump to json per specter formatting \n",
    "    \n",
    "    dat = pd.read_csv(fn, encoding = 'ISO-8859-1')\n",
    "    dat = dat.dropna(subset = ['Abstract']) # drop the papers with null abstracts after parsing to retain the index?\n",
    "    dat.columns = map(str.lower, dat.columns) # lowercase for compatability w/ specter\n",
    "    dat = dat.reset_index() \n",
    "    dat = dat.rename(columns={'index': 'paper_id'})\n",
    "    new_json = dat[['title', 'abstract', 'paper_id']].to_json(orient = 'index')\n",
    "    parsed_json = json.loads(new_json)\n",
    "    #json.dumps(parsed_json, indent = 2)\n",
    "    with open(out_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(parsed_json, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # also create the '*.ids' file\n",
    "    \n",
    "    dat.to_csv(out_ids, columns=[], header=False)\n",
    "    \n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "out_dir=embed_json\n",
    "mkdir -p ${out_dir}\n",
    "\n",
    "\n",
    "for f in $(ls datasets_json/*ids) |\n",
    "do\n",
    "    f=$(basename ${f} | sed 's/\\.ids//g')\n",
    "    echo ${f}\n",
    "    \n",
    "    \n",
    "    python3 scripts/embed.py \\\n",
    "        --ids datasets_json/${f}.ids --metadata datasets_json/${f}.json \\\n",
    "        --model ./model.tar.gz \\\n",
    "        --output-file ${out_dir}/${f}.jsonl \\\n",
    "        --vocab-dir data/vocab/ \\\n",
    "        --batch-size 96 \\\n",
    "        --cuda-device 2\n",
    "\n",
    "done\n",
    "echo \"Done!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}